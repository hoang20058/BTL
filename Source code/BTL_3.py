import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
BASE_DIR = os.path.join('REPORT_BTL', 'BTL3_File')  # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c mong mu·ªën
os.makedirs(BASE_DIR, exist_ok=True)

def load_and_preprocess_data(file_path):
    """
    ƒê·ªçc v√† chu·∫©n h√≥a d·ªØ li·ªáu s·ªë t·ª´ file CSV.
    """
    df = pd.read_csv(file_path, header=2)

    # Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt s·ªë, b·ªè c·ªôt 'Age' n·∫øu c√≥
    numeric_df = df.select_dtypes(include='number').drop(columns=['Age'], errors='ignore')

    # Thay th·∫ø gi√° tr·ªã thi·∫øu b·∫±ng 0
    numeric_df = numeric_df.fillna(0)

    # Chu·∫©n h√≥a
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(numeric_df)

    return df, numeric_df, scaled_data


def find_optimal_k(data):
    """
    T√¨m s·ªë c·ª•m t·ªëi ∆∞u b·∫±ng Elbow Method v√† l∆∞u bi·ªÉu ƒë·ªì.
    """
    wcss = []
    for i in range(1, 11):
        kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)
        kmeans.fit(data) 
        wcss.append(kmeans.inertia_)


    # V·∫Ω bi·ªÉu ƒë·ªì Elbow Method
    plt.figure(figsize=(8, 5))
    plt.plot(range(1, 11), wcss, marker='o')
    plt.title(f"Elbow Method - Ch·ªçn s·ªë c·ª•m t·ªëi ∆∞u k ")
    plt.xlabel("S·ªë c·ª•m (k)")
    plt.ylabel("WCSS")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(BASE_DIR, "Elbow_Method.png"), dpi=300)
    plt.close()
    optimal_k = 4
    return optimal_k

def perform_kmeans(data, k):
    """
    Th·ª±c hi·ªán ph√¢n c·ª•m KMeans.
    """
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(data)
    
    # Ch·ªânh l·∫°i nh√£n ƒë·ªÉ b·∫Øt ƒë·∫ßu t·ª´ 1 thay v√¨ 0
    cluster_labels += 1
    
    return cluster_labels


def reduce_with_pca(data):
    """
    Gi·∫£m chi·ªÅu d·ªØ li·ªáu b·∫±ng PCA (2 th√†nh ph·∫ßn ch√≠nh).
    """
    pca = PCA(n_components=2)
    return pca.fit_transform(data)

def plot_clusters(pca_data, cluster_labels):
    """
    V·∫Ω bi·ªÉu ƒë·ªì ph√¢n c·ª•m sau PCA.
    """
    df_plot = pd.DataFrame(pca_data, columns=['PC1', 'PC2'])
    df_plot['Cluster'] = cluster_labels

    plt.figure(figsize=(10, 6))
    sns.scatterplot(x='PC1', y='PC2', hue='Cluster', palette='Set2', data=df_plot, s=100)
    plt.title("Bi·ªÉu ƒë·ªì ph√¢n c·ª•m b·∫±ng PCA (2D)")
    plt.xlabel("Th√†nh ph·∫ßn 1")
    plt.ylabel("Th√†nh ph·∫ßn 2")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(BASE_DIR, "KMeans_PCA_Clusters.png"), dpi=300)
    plt.close()
    print(f"Successful plot Kmean PCA")

def save_cluster_analysis(result_df, output_file):
    """
    L∆∞u th√¥ng tin ph√¢n t√≠ch c√°c c·ª•m v√†o file TXT.
    """
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("--- PH√ÇN T√çCH C·ª§M C·∫¶U TH·ª¶ ---\n")
        for c in sorted(result_df['Cluster'].unique()):
            group = result_df[result_df['Cluster'] == c]
            f.write(f"\n=============================\n")
            f.write(f"‚úÖ C·ª•m {c} - S·ªë c·∫ßu th·ªß: {len(group)}\n")

            if 'Name' in group.columns:
                f.write("üîπ T√™n c·∫ßu th·ªß: " + ", ".join(group['Name'].astype(str).tolist()) + "\n")
            else:
                f.write("Kh√¥ng c√≥ c·ªôt 'Name' ƒë·ªÉ hi·ªÉn th·ªã t√™n.\n")

            # T√≠nh trung b√¨nh cho c√°c ch·ªâ s·ªë s·ªë h·ªçc
            stats = group.select_dtypes(include='number').mean().round(2)
            f.write("üîç Trung b√¨nh ch·ªâ s·ªë c·ª•m:\n")
            f.write(stats.to_string())
            f.write("\n")

        print(f"Successful Saved to {output_file}")

def main():
    file_path = "Table_EPL.csv"

    # B∆∞·ªõc 1: Load v√† chu·∫©n h√≥a d·ªØ li·ªáu
    df_raw, df_numeric, scaled_data = load_and_preprocess_data(file_path)

    # B∆∞·ªõc 2: T√¨m s·ªë c·ª•m t·ªëi ∆∞u
    optimal_k = find_optimal_k(scaled_data)

    # B∆∞·ªõc 3: Ph√¢n c·ª•m KMeans
    clusters = perform_kmeans(scaled_data, optimal_k)

    # B∆∞·ªõc 4: Gi·∫£m chi·ªÅu b·∫±ng PCA
    pca_data = reduce_with_pca(scaled_data)

    # B∆∞·ªõc 5: V·∫Ω bi·ªÉu ƒë·ªì ph√¢n c·ª•m
    plot_clusters(pca_data, clusters)

    # B∆∞·ªõc 6: G·∫Øn nh√£n c·ª•m v√†o DataFrame g·ªëc v√† l∆∞u
    result_df = df_raw.loc[df_numeric.index].copy()
    result_df['Cluster'] = clusters
    result_df.to_csv(os.path.join(BASE_DIR, "Table_EPL_Clustered.csv"), index=False, encoding='utf-8-sig')
    print(f"Successful save to csv file")

    # B∆∞·ªõc 7: Ghi ph√¢n t√≠ch c·ª•m v√†o file
    analysis_file = os.path.join(BASE_DIR, "Cluster_Analysis.txt")
    save_cluster_analysis(result_df, analysis_file)

if __name__ == "__main__":
    main()

